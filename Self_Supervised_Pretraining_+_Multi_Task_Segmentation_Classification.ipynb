{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNU0wTzeISsr1wwYBd0gTxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aoctavia/Self-Supervised-Pretraining-Multi-Task-Segmentation-Classification/blob/main/Self_Supervised_Pretraining_%2B_Multi_Task_Segmentation_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gambaran arsitektur & alur\n",
        "1. Self‑supervised pretraining (SSL) di semua gambar (tanpa label) → encoder kuat\n",
        "\n",
        "2. Fine‑tune classifier (tumor vs no tumor → lalu 4 kelas)\n",
        "\n",
        "3. Generate CAM dari classifier → pseudo‑mask\n",
        "\n",
        "4. Train segmentation head (UNet‑style decoder) dengan Dice + BCE pakai pseudo‑mask\n",
        "\n",
        "5. Joint training (shared encoder) dengan loss gabungan:\n",
        "\n",
        "$$\n",
        "\\mathscr{L} = \\lambda_{\\mathrm{cls}} \\cdot \\mathrm{CE} + \\lambda_{\\mathrm{seg}} \\cdot (\\mathrm{Dice} + \\mathrm{BCE})\n",
        "$$\n",
        "\n",
        "\n",
        "6. Robustness: augmentasi berbasis fisika MRI (noise, motion blur, bias‑field) + evaluasi"
      ],
      "metadata": {
        "id": "ksE9gul4u-NN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Setup & Mount Drive"
      ],
      "metadata": {
        "id": "1bAL_NllvYz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fhuXkjZMu4qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c7bb54-c34c-47e2-c4f1-adf1c211869f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug 13 12:32:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Colab: Runtime -> Change runtime type -> GPU (T4/L4/A100)\n",
        "!nvidia-smi\n",
        "\n",
        "!pip -q install timm==1.0.3 torchmetrics==1.4.0 albumentations==1.4.7 einops==0.8.0 grad-cam==1.5.0\n",
        "!pip -q install lightning==2.4.0  # opsional, kalau mau pakai PyTorch Lightning\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain\"  # ganti sesuai folder dataset\n",
        "WORK_DIR = \"/content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project\"\n",
        "\n",
        "!mkdir -p \"{WORK_DIR}/checkpoints\" \"{WORK_DIR}/pseudo_masks\" \"{WORK_DIR}/logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Konfigurasi  & Util"
      ],
      "metadata": {
        "id": "Urd59I9svBSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\")\n",
        "\n",
        "def find_split_dir(root, split_kind=\"train\"):\n",
        "    cands = [\"Training\",\"Train\",\"training\",\"train\"] if split_kind==\"train\" else [\"Testing\",\"Test\",\"testing\",\"test\"]\n",
        "    for c in cands:\n",
        "        d = os.path.join(root, c)\n",
        "        if os.path.isdir(d):\n",
        "            return d\n",
        "    return None\n",
        "\n",
        "def detect_classes(dir_path):\n",
        "    return sorted([d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, d))])\n",
        "\n",
        "def list_images_in_dir(dir_path, classes, recursive=False):\n",
        "    items = []\n",
        "    for c in classes:\n",
        "        cls_dir = os.path.join(dir_path, c)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            alts = [d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path,d)) and d.lower()==c.lower()]\n",
        "            if alts:\n",
        "                cls_dir = os.path.join(dir_path, alts[0])\n",
        "            else:\n",
        "                print(f\"WARNING: folder kelas tidak ada: {cls_dir}\")\n",
        "                continue\n",
        "        pattern = \"**/*\" if recursive else \"*\"\n",
        "        files = []\n",
        "        for ext in IMG_EXTS:\n",
        "            files.extend(glob.glob(os.path.join(cls_dir, pattern + ext), recursive=recursive))\n",
        "        if len(files)==0 and not recursive:\n",
        "            for ext in IMG_EXTS:\n",
        "                files.extend(glob.glob(os.path.join(cls_dir, \"**\", \"*\" + ext), recursive=True))\n",
        "        if len(files)==0:\n",
        "            print(f\"WARNING: tidak ada file gambar di {cls_dir}\")\n",
        "        items.extend((p, c) for p in files)\n",
        "    return items\n",
        "\n",
        "def build_items(DATA_DIR):\n",
        "    train_dir = find_split_dir(DATA_DIR, \"train\")\n",
        "    test_dir  = find_split_dir(DATA_DIR, \"test\")\n",
        "    if train_dir and test_dir:\n",
        "        classes = detect_classes(train_dir)\n",
        "        train_items = list_images_in_dir(train_dir, classes)\n",
        "        test_items  = list_images_in_dir(test_dir,  classes)\n",
        "        return train_items, test_items, classes, \"pre-split\"\n",
        "\n",
        "    classes = detect_classes(DATA_DIR)\n",
        "    if classes:\n",
        "        all_items = list_images_in_dir(DATA_DIR, classes)\n",
        "        y_all = [c for _, c in all_items]\n",
        "        X = [p for p,_ in all_items]\n",
        "        cls2idx = {c:i for i,c in enumerate(sorted(set(y_all)))}\n",
        "        y_idx = np.array([cls2idx[c] for c in y_all])\n",
        "\n",
        "        X_train, X_tmp, y_train, y_tmp = train_test_split(X, y_idx, test_size=0.30, random_state=42, stratify=y_idx)\n",
        "        X_val,   X_test, y_val,  y_test= train_test_split(X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp)\n",
        "\n",
        "        train_items = list(zip(X_train, [list(cls2idx.keys())[list(cls2idx.values()).index(y)] for y in y_train]))\n",
        "        val_items   = list(zip(X_val,   [list(cls2idx.keys())[list(cls2idx.values()).index(y)] for y in y_val]))\n",
        "        test_items  = list(zip(X_test,  [list(cls2idx.keys())[list(cls2idx.values()).index(y)] for y in y_test]))\n",
        "        return (train_items, test_items, classes, \"no-split\", val_items)\n",
        "\n",
        "    raise FileNotFoundError(\"Tidak menemukan struktur dataset di DATA_DIR.\")\n",
        "\n",
        "built = build_items(DATA_DIR)\n",
        "\n",
        "if built[3] == \"pre-split\":\n",
        "    train_items, test_items, CLASSES, _ = built\n",
        "    CLASS2IDX = {c:i for i,c in enumerate(CLASSES)}\n",
        "    train_paths = [(p, CLASS2IDX[y]) for p,y in train_items]\n",
        "\n",
        "    y_all = np.array([y for _,y in train_paths])\n",
        "    can_stratify = all((y_all==k).sum() >= 2 for k in np.unique(y_all))\n",
        "    if can_stratify and len(train_paths) >= 10:\n",
        "        train_paths, val_paths = train_test_split(train_paths, test_size=0.15, random_state=42, stratify=y_all)\n",
        "    else:\n",
        "        print(\"NOTE: stratify OFF (kelas terlalu sedikit/dataset kecil).\")\n",
        "        train_paths, val_paths = train_test_split(train_paths, test_size=max(1, int(0.15*len(train_paths))), random_state=42, shuffle=True)\n",
        "    test_paths  = [(p, CLASS2IDX[y]) for p,y in test_items]\n",
        "\n",
        "else:\n",
        "    train_items, test_items, CLASSES, _, val_items = built\n",
        "    CLASS2IDX = {c:i for i,c in enumerate(CLASSES)}\n",
        "    train_paths = [(p, CLASS2IDX[y]) for p,y in train_items]\n",
        "    val_paths   = [(p, CLASS2IDX[y]) for p,y in val_items]\n",
        "    test_paths  = [(p, CLASS2IDX[y]) for p,y in test_items]\n",
        "\n",
        "print(\"Classes:\", CLASSES)\n",
        "print(\"Counts -> train:\", len(train_paths), \"val:\", len(val_paths), \"test:\", len(test_paths))\n"
      ],
      "metadata": {
        "id": "G5psBpZPGZbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1501be88-7a07-48ec-902d-21f1293680ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
            "Counts -> train: 4855 val: 857 test: 1311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cell diagnostik"
      ],
      "metadata": {
        "id": "4W27-pfWHB8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"Ada folder ini? TRAIN:\", os.path.isdir(os.path.join(DATA_DIR, \"Training\")),\n",
        "      \"TEST:\", os.path.isdir(os.path.join(DATA_DIR, \"Testing\")))\n",
        "\n",
        "# Tunjukkan kelas yang terdeteksi di training split\n",
        "train_dir = None\n",
        "for d in [\"Training\",\"Train\",\"training\",\"train\"]:\n",
        "    if os.path.isdir(os.path.join(DATA_DIR, d)):\n",
        "        train_dir = os.path.join(DATA_DIR, d); break\n",
        "print(\"Training dir:\", train_dir)\n",
        "if train_dir:\n",
        "    print(\"Subfolder kelas di Training dir:\", [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir,d))])\n",
        "\n",
        "# Hitung file yang cocok ekstensi\n",
        "IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".JPG\",\".JPEG\",\".PNG\")\n",
        "if train_dir:\n",
        "    total = 0\n",
        "    for cls in os.listdir(train_dir):\n",
        "        cls_dir = os.path.join(train_dir, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        cnt = 0\n",
        "        for ext in IMG_EXTS:\n",
        "            cnt += len(glob.glob(os.path.join(cls_dir, f\"*{ext}\")))\n",
        "            cnt += len(glob.glob(os.path.join(cls_dir, \"**\", f\"*{ext}\"), recursive=True))\n",
        "        print(f\"- {cls}: {cnt} files\")\n",
        "        total += cnt\n",
        "    print(\"Total files in Training:\", total)\n",
        "\n",
        "# Sanity: cetak 3 contoh path dari train_paths/val_paths/test_paths\n",
        "try:\n",
        "    print(\"len(train_paths), len(val_paths), len(test_paths):\", len(train_paths), len(val_paths), len(test_paths))\n",
        "    print(\"sample train:\", train_paths[0][0] if len(train_paths)>0 else \"EMPTY\")\n",
        "    print(\"sample val  :\", val_paths[0][0]   if len(val_paths)>0   else \"EMPTY\")\n",
        "    print(\"sample test :\", test_paths[0][0]  if len(test_paths)>0  else \"EMPTY\")\n",
        "except NameError as e:\n",
        "    print(\"Variable belum ada (jalankan Step-2 dulu).\", e)\n"
      ],
      "metadata": {
        "id": "i_qCPsnQHBWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceed0bc-5ff4-4eb9-ad34-76aa01a45b2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR: /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain\n",
            "Ada folder ini? TRAIN: True TEST: True\n",
            "Training dir: /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain/Training\n",
            "Subfolder kelas di Training dir: ['meningioma', 'glioma', 'pituitary', 'notumor']\n",
            "- meningioma: 2678 files\n",
            "- glioma: 2642 files\n",
            "- pituitary: 2914 files\n",
            "- notumor: 3190 files\n",
            "Total files in Training: 11424\n",
            "len(train_paths), len(val_paths), len(test_paths): 4855 857 1311\n",
            "sample train: /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain/Training/glioma/Tr-gl_0798.jpg\n",
            "sample val  : /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain/Training/notumor/Tr-no_1186.jpg\n",
            "sample test : /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain/Testing/glioma/Te-glTr_0001.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pakai CLASS2IDX dari Step-2\n",
        "IDX2CLASS = {v:k for k,v in CLASS2IDX.items()}\n",
        "\n",
        "DISPLAY_MAP = {\n",
        "    \"pituitary\": \"pituitary_tumor\",\n",
        "    \"notumor\": \"no_tumor\",\n",
        "    \"glioma\": \"glioma\",\n",
        "    \"meningioma\": \"meningioma\",\n",
        "}\n",
        "\n",
        "def display_name(idx: int) -> str:\n",
        "    raw = IDX2CLASS[idx]\n",
        "    return DISPLAY_MAP.get(raw, raw)\n"
      ],
      "metadata": {
        "id": "bj22tGmKHY3M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = [display_name(i) for i in range(len(CLASS2IDX))]\n"
      ],
      "metadata": {
        "id": "hkDRgNI3Hbqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Dataset loader (supervised & SSL)"
      ],
      "metadata": {
        "id": "6fBvSYJGvqms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "IMG_SIZE   = 224\n",
        "BATCH_SSL  = 128\n",
        "BATCH_SUP  = 32\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "aug_train = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.10, rotate_limit=15, border_mode=0, p=0.7),\n",
        "    A.RandomBrightnessContrast(0.15, 0.15, p=0.5),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.MotionBlur(blur_limit=5, p=0.3),\n",
        "    A.ImageCompression(quality_lower=85, p=0.3),\n",
        "    A.Normalize(),\n",
        "    albumentations.pytorch.ToTensorV2(),\n",
        "])\n",
        "\n",
        "aug_val = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(),\n",
        "    albumentations.pytorch.ToTensorV2(),\n",
        "])\n",
        "\n",
        "class SupervisedMRIDataset(Dataset):\n",
        "    def __init__(self, items, aug):\n",
        "        self.items = items\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        path, y = self.items[i]\n",
        "        img = np.array(Image.open(path).convert(\"RGB\"))\n",
        "        img = self.aug(image=img)[\"image\"]\n",
        "        return img, y, path\n",
        "\n",
        "ssl_aug = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.5, 1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
        "    A.GaussNoise(var_limit=(5.0, 25.0), p=0.5),\n",
        "    A.MotionBlur(5, p=0.3),\n",
        "    A.Normalize(),\n",
        "    albumentations.pytorch.ToTensorV2(),\n",
        "])\n",
        "\n",
        "class SSLDataset(Dataset):\n",
        "    def __init__(self, items, aug):\n",
        "        self.paths = [p for p,_ in items]\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        path = self.paths[i]\n",
        "        img  = np.array(Image.open(path).convert(\"RGB\"))\n",
        "        v1 = self.aug(image=img)[\"image\"]\n",
        "        v2 = self.aug(image=img)[\"image\"]\n",
        "        return v1, v2\n",
        "\n",
        "# gunakan train_paths, val_paths, test_paths dari Step-2\n",
        "sup_tr = SupervisedMRIDataset(train_paths, aug_train)\n",
        "sup_va = SupervisedMRIDataset(val_paths,   aug_val)\n",
        "sup_te = SupervisedMRIDataset(test_paths,  aug_val)\n",
        "\n",
        "tr_dl = DataLoader(sup_tr, batch_size=BATCH_SUP, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "va_dl = DataLoader(sup_va, batch_size=BATCH_SUP, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "te_dl = DataLoader(sup_te, batch_size=BATCH_SUP, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "ssl_items = train_paths + val_paths + test_paths\n",
        "ssl_ds = SSLDataset(ssl_items, ssl_aug)\n",
        "ssl_dl = DataLoader(ssl_ds, batch_size=BATCH_SSL, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# sanity check\n",
        "xb, yb, pb = next(iter(tr_dl))\n",
        "print(\"Supervised batch:\", xb.shape, \"labels raw:\", yb[:5].tolist(), \"labels pretty:\", [display_name(int(i)) for i in yb[:5]])\n",
        "v1, v2 = next(iter(ssl_dl))\n",
        "print(\"SSL batch:\", v1.shape, v2.shape)\n"
      ],
      "metadata": {
        "id": "XNjSfbf7v6Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7d8b43-59a7-4ae7-de18-d9cb7a4cd374"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised batch: torch.Size([32, 3, 224, 224]) labels raw: [0, 2, 0, 0, 0] labels pretty: ['glioma', 'no_tumor', 'glioma', 'glioma', 'glioma']\n",
            "SSL batch: torch.Size([128, 3, 224, 224]) torch.Size([128, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Self‑Supervised Pretraining (SimCLR sederhana)"
      ],
      "metadata": {
        "id": "ycjqx_xgv8Nu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### kode dibawah ini akan crash jika memakai colabs free ! JANGAN DI RUN JIKA PAKAI FREE MODE !"
      ],
      "metadata": {
        "id": "GxMAFvu3KFSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-4: SSL Pretraining (SimCLR) ====\n",
        "import copy, torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "# (opsional) ubah num_workers agar aman di Colab\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim, hid=2048, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hid), nn.ReLU(inplace=True),\n",
        "            nn.Linear(hid, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder_name=\"resnet50\", proj_out=128):\n",
        "        super().__init__()\n",
        "        self.encoder = timm.create_model(encoder_name, pretrained=False, num_classes=0)  # feature vector\n",
        "        in_dim = self.encoder.num_features\n",
        "        self.proj = ProjectionHead(in_dim, 2048, proj_out)\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z = F.normalize(self.proj(h), dim=1)\n",
        "        return h, z\n",
        "\n",
        "def info_nce(z1, z2, tau=0.2):\n",
        "    N = z1.size(0)\n",
        "    z1 = F.normalize(z1, dim=1); z2 = F.normalize(z2, dim=1)\n",
        "    reps = torch.cat([z1, z2], dim=0)         # (2N, d)\n",
        "    sim  = reps @ reps.T                      # cosine (karena sudah normalized)\n",
        "    labels = torch.cat([torch.arange(N), torch.arange(N)], dim=0).to(z1.device)\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "    mask = torch.eye(labels.shape[0], dtype=torch.bool, device=z1.device)\n",
        "    labels = labels[~mask].view(labels.shape[0], -1)\n",
        "    sim    = sim[~mask].view(sim.shape[0], -1)\n",
        "    pos    = sim[labels.bool()].view(labels.shape[0], -1)\n",
        "    neg    = sim[~labels.bool()].view(labels.shape[0], -1)\n",
        "    logits = torch.cat([pos, neg], dim=1) / tau\n",
        "    y = torch.zeros(logits.size(0), dtype=torch.long, device=z1.device)\n",
        "    return F.cross_entropy(logits, y)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCH_SSL = 10        # mulai rendah dulu; nanti bisa ditingkatkan (20–50)\n",
        "\n",
        "simclr = SimCLR(\"resnet50\").to(DEVICE)\n",
        "opt_ssl = torch.optim.AdamW(simclr.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(EPOCH_SSL):\n",
        "    simclr.train()\n",
        "    total = 0\n",
        "    for v1, v2 in ssl_dl:                 # dari Step-3\n",
        "        v1, v2 = v1.to(DEVICE), v2.to(DEVICE)\n",
        "        _, z1 = simclr(v1)\n",
        "        _, z2 = simclr(v2)\n",
        "        loss = info_nce(z1, z2, tau=0.2)\n",
        "        opt_ssl.zero_grad(); loss.backward(); opt_ssl.step()\n",
        "        total += loss.item()*v1.size(0)\n",
        "    print(f\"[SSL] epoch {epoch+1}/{EPOCH_SSL} loss={total/len(ssl_ds):.4f}\")\n",
        "\n",
        "# simpan encoder hasil pretraining\n",
        "ssl_encoder = copy.deepcopy(simclr.encoder).eval().to(DEVICE)\n",
        "enc_path = f\"{WORK_DIR}/checkpoints/ssl_encoder_resnet50.pt\"\n",
        "torch.save(ssl_encoder.state_dict(), enc_path)\n",
        "print(\"Saved:\", enc_path)\n"
      ],
      "metadata": {
        "id": "OoFsVc1Jv-4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Opsi A — “Safe Mode” SimCLR (lebih ringan, tetap SimCLR)"
      ],
      "metadata": {
        "id": "JRs4PTSKKJAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- TUNE AGAR HEMAT MEMORI ----\n",
        "NUM_WORKERS   = 2          # kurangi worker\n",
        "BATCH_SSL     = 32         # TURUNKAN dari 128 -> 32 (atau 16 kalau masih crash)\n",
        "IMG_SIZE      = 192        # 224 -> 192 (atau 160 kalau perlu)\n",
        "EPOCH_SSL     = 5          # mulai kecil dulu, bisa ulang beberapa kali\n",
        "\n",
        "# 1) pakai subset data untuk SSL (mis. 15k sampel)\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np, math\n",
        "\n",
        "max_ssl_samples = 15000      # turunkan lagi bila perlu (8000/4000)\n",
        "all_idx = np.arange(len(ssl_ds))\n",
        "np.random.shuffle(all_idx)\n",
        "ssl_subset_idx = all_idx[:min(max_ssl_samples, len(ssl_ds))]\n",
        "ssl_dl = DataLoader(\n",
        "    Subset(ssl_ds, ssl_subset_idx),\n",
        "    batch_size=BATCH_SSL, shuffle=True,\n",
        "    num_workers=NUM_WORKERS, pin_memory=False,  # pin_memory False mengurangi crash di Colab\n",
        "    persistent_workers=False, prefetch_factor=2\n",
        ")\n",
        "\n",
        "# 2) ganti encoder lebih kecil (resnet18) biar ringan\n",
        "import timm, torch, torch.nn as nn, torch.nn.functional as F, copy\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim, hid=512, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hid), nn.ReLU(inplace=True),\n",
        "            nn.Linear(hid, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder_name=\"resnet18\", proj_out=128):\n",
        "        super().__init__()\n",
        "        self.encoder = timm.create_model(encoder_name, pretrained=False, num_classes=0)\n",
        "        self.in_dim = self.encoder.num_features\n",
        "        self.proj = ProjectionHead(self.in_dim, 512, proj_out)\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z = F.normalize(self.proj(h), dim=1)\n",
        "        return h, z\n",
        "\n",
        "def info_nce(z1, z2, tau=0.2):\n",
        "    N = z1.size(0)\n",
        "    z1 = F.normalize(z1, dim=1); z2 = F.normalize(z2, dim=1)\n",
        "    reps = torch.cat([z1, z2], dim=0)   # (2N,d)\n",
        "    sim  = reps @ reps.T                # cosine (sudah norm)\n",
        "    labels = torch.arange(N, device=z1.device)\n",
        "    labels = torch.cat([labels, labels], dim=0)\n",
        "    pos_mask = (labels.unsqueeze(0)==labels.unsqueeze(1)).float()\n",
        "    mask = torch.eye(pos_mask.shape[0], dtype=torch.bool, device=z1.device)\n",
        "    pos = sim[pos_mask.bool()].view(pos_mask.shape[0], -1)\n",
        "    neg = sim[~pos_mask.bool()].view(pos_mask.shape[0], -1)\n",
        "    logits = torch.cat([pos, neg], dim=1) / tau\n",
        "    y = torch.zeros(logits.size(0), dtype=torch.long, device=z1.device)\n",
        "    return F.cross_entropy(logits, y)\n",
        "\n",
        "# 3) mixed precision + gradient accumulation\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "accumulate_steps = 2  # simulasikan batch lebih besar tanpa OOM\n",
        "\n",
        "simclr = SimCLR(\"resnet18\").to(DEVICE)\n",
        "opt_ssl = torch.optim.AdamW(simclr.parameters(), lr=8e-4, weight_decay=1e-4)\n",
        "scaler = GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "# optional: kurangi fragmentasi memori\n",
        "import os, torch\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
        "\n",
        "for epoch in range(EPOCH_SSL):\n",
        "    simclr.train()\n",
        "    running, nimg, step = 0.0, 0, 0\n",
        "    opt_ssl.zero_grad(set_to_none=True)\n",
        "\n",
        "    for v1, v2 in ssl_dl:\n",
        "        v1, v2 = v1.to(DEVICE, non_blocking=True), v2.to(DEVICE, non_blocking=True)\n",
        "        with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            _, z1 = simclr(v1)\n",
        "            _, z2 = simclr(v2)\n",
        "            loss = info_nce(z1, z2, tau=0.2) / accumulate_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        step += 1\n",
        "        if step % accumulate_steps == 0:\n",
        "            scaler.step(opt_ssl)\n",
        "            scaler.update()\n",
        "            opt_ssl.zero_grad(set_to_none=True)\n",
        "\n",
        "        running += loss.item()*accumulate_steps*v1.size(0)\n",
        "        nimg += v1.size(0)\n",
        "\n",
        "        # flush cache sesekali\n",
        "        if DEVICE==\"cuda\" and (step % 50 == 0):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"[SSL] epoch {epoch+1}/{EPOCH_SSL} loss={running/max(1,nimg):.4f}\")\n",
        "\n",
        "# simpan encoder\n",
        "ssl_encoder = copy.deepcopy(simclr.encoder).eval().to(DEVICE)\n",
        "enc_path = f\"{WORK_DIR}/checkpoints/ssl_encoder_resnet18.pt\"\n",
        "torch.save(ssl_encoder.state_dict(), enc_path)\n",
        "print(\"Saved:\", enc_path)\n"
      ],
      "metadata": {
        "id": "GATcNTjIKG20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6788d9e9-83ad-44f6-8f85-2f66d9bfb4e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3613165050.py:67: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=(DEVICE==\"cuda\"))\n",
            "/tmp/ipython-input-3613165050.py:80: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(DEVICE==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SSL] epoch 1/5 loss=2.3234\n",
            "[SSL] epoch 2/5 loss=1.7254\n",
            "[SSL] epoch 3/5 loss=1.5008\n",
            "[SSL] epoch 4/5 loss=1.3826\n",
            "[SSL] epoch 5/5 loss=1.3018\n",
            "Saved: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/checkpoints/ssl_encoder_resnet18.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Opsi B — Ganti ke SimSiam (lebih ramah batch kecil)\n",
        "SimSiam tidak butuh negative pairs → jauh lebih stabil di batch kecil (16–32). Kalau mau, kamu bisa langsung pakai SimSiam ketimbang SimCLR. (Aku bisa kasih blok kode SimSiam siap tempel juga.)"
      ],
      "metadata": {
        "id": "GCyD6n0AKhdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Fine‑tune classifier (4 kelas)"
      ],
      "metadata": {
        "id": "8Ldta9j4wBJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = len(CLASS2IDX)\n",
        "enc_path = f\"{WORK_DIR}/checkpoints/ssl_encoder_resnet18.pt\"  # dari step-4\n",
        "\n",
        "# (opsional) pretty names\n",
        "IDX2CLASS = {v:k for k,v in CLASS2IDX.items()}\n",
        "DISPLAY_MAP = {\"pituitary\":\"pituitary_tumor\", \"notumor\":\"no_tumor\"}\n",
        "def display_name(i):\n",
        "    raw = IDX2CLASS[i];\n",
        "    return DISPLAY_MAP.get(raw, raw)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        in_dim = self.encoder.num_features\n",
        "        self.cls = nn.Linear(in_dim, num_classes)\n",
        "    def forward(self, x):\n",
        "        feat = self.encoder(x)\n",
        "        logits = self.cls(feat)\n",
        "        return logits, feat\n",
        "\n",
        "# load encoder SSL (resnet18)\n",
        "encoder_ft = timm.create_model(\"resnet18\", pretrained=False, num_classes=0)\n",
        "encoder_ft.load_state_dict(torch.load(enc_path, map_location=\"cpu\"))\n",
        "model_cls = Classifier(encoder_ft, NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "opt = torch.optim.AdamW(model_cls.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch(dl, train=True):\n",
        "    model_cls.train(train)\n",
        "    tot, corr, n = 0.0, 0, 0\n",
        "    for x,y,_ in dl:\n",
        "        x = x.to(DEVICE); y = torch.as_tensor(y, device=DEVICE)\n",
        "        logits,_ = model_cls(x)\n",
        "        loss = criterion(logits, y)\n",
        "        if train:\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "        tot += loss.item()*x.size(0)\n",
        "        corr += (logits.argmax(1)==y).sum().item()\n",
        "        n += x.size(0)\n",
        "    return tot/n, corr/n\n",
        "\n",
        "EPOCH_CLS = 8  # bisa tambah setelah jalan stabil\n",
        "for ep in range(EPOCH_CLS):\n",
        "    tr_l,tr_a = run_epoch(tr_dl, True)\n",
        "    va_l,va_a = run_epoch(va_dl, False)\n",
        "    print(f\"[CLS] {ep+1}/{EPOCH_CLS}  train {tr_l:.4f}/{tr_a:.3f}  val {va_l:.4f}/{va_a:.3f}\")\n",
        "\n",
        "# evaluasi test\n",
        "model_cls.eval()\n",
        "all_y, all_p = [], []\n",
        "with torch.no_grad():\n",
        "    for x,y,_ in te_dl:\n",
        "        x = x.to(DEVICE)\n",
        "        probs = F.softmax(model_cls(x)[0], dim=1).cpu().numpy()\n",
        "        all_p.append(probs); all_y.extend(y)\n",
        "all_p = np.vstack(all_p)\n",
        "pred = all_p.argmax(1)\n",
        "\n",
        "target_names = [display_name(i) for i in range(NUM_CLASSES)]\n",
        "print(classification_report(all_y, pred, target_names=target_names, digits=4))\n",
        "print(confusion_matrix(all_y, pred))\n"
      ],
      "metadata": {
        "id": "CcuwwOtcwDtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be98859-0249-4a1b-9abd-55cf64f4abc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 1/8  train 0.8573/0.699  val 0.6195/0.776\n",
            "[CLS] 2/8  train 0.5262/0.819  val 0.3974/0.861\n",
            "[CLS] 3/8  train 0.4385/0.844  val 0.4716/0.826\n",
            "[CLS] 4/8  train 0.4024/0.856  val 0.3250/0.869\n",
            "[CLS] 5/8  train 0.3670/0.865  val 0.2715/0.897\n",
            "[CLS] 6/8  train 0.3362/0.880  val 0.2563/0.904\n",
            "[CLS] 7/8  train 0.3136/0.888  val 0.2367/0.911\n",
            "[CLS] 8/8  train 0.2958/0.894  val 0.2414/0.907\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "         glioma     0.8384    0.9167    0.8758       300\n",
            "     meningioma     0.8667    0.6797    0.7619       306\n",
            "       no_tumor     0.9076    0.9704    0.9379       405\n",
            "pituitary_tumor     0.9097    0.9400    0.9246       300\n",
            "\n",
            "       accuracy                         0.8833      1311\n",
            "      macro avg     0.8806    0.8767    0.8751      1311\n",
            "   weighted avg     0.8827    0.8833    0.8796      1311\n",
            "\n",
            "[[275  25   0   0]\n",
            " [ 31 208  40  27]\n",
            " [  5   6 393   1]\n",
            " [ 17   1   0 282]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Generate pseudo‑mask via Grad‑CAM"
      ],
      "metadata": {
        "id": "_QxDgZt-wFW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-6 (fixed): Grad-CAM -> pseudo-mask ====\n",
        "!pip -q install grad-cam==1.5.0\n",
        "\n",
        "import os, numpy as np, torch\n",
        "from PIL import Image\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_cls.eval()  # eval mode, tapi JANGAN pakai torch.no_grad() saat CAM\n",
        "\n",
        "# Kelas tumor (exclude no_tumor/notumor)\n",
        "tumor_class_names = [k for k in CLASS2IDX.keys() if k.lower() not in [\"no_tumor\",\"notumor\"]]\n",
        "tumor_class_idx = set(CLASS2IDX[k] for k in tumor_class_names)\n",
        "\n",
        "# Target layer utk ResNet18\n",
        "target_layer = model_cls.encoder.layer4[-1]\n",
        "\n",
        "os.makedirs(f\"{WORK_DIR}/pseudo_masks\", exist_ok=True)\n",
        "\n",
        "def tensor_to_img01(t):\n",
        "    x = t.permute(1,2,0).detach().cpu().numpy()\n",
        "    x = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
        "    return x\n",
        "\n",
        "def save_mask_for_batch(x, paths):\n",
        "    # x: [B,3,H,W] on DEVICE\n",
        "    # Prediksi dulu utk ambil target kelas\n",
        "    logits, _ = model_cls(x)\n",
        "    preds = logits.argmax(1).detach().cpu().numpy()\n",
        "\n",
        "    # Grad-CAM perlu gradient -> JANGAN pakai no_grad di sini\n",
        "    with GradCAM(model=model_cls, target_layers=[target_layer]) as cam:\n",
        "        for i, path in enumerate(paths):\n",
        "            if int(preds[i]) not in tumor_class_idx:\n",
        "                continue\n",
        "            targets = [ClassifierOutputTarget(int(preds[i]))]\n",
        "            heatmap = cam(input_tensor=x[i].unsqueeze(0), targets=targets)[0]  # [H,W] in [0,1]\n",
        "\n",
        "            # Threshold konservatif jadi pseudo-mask biner\n",
        "            thr = np.percentile(heatmap, 75.0)\n",
        "            mask = (heatmap >= thr).astype(np.uint8) * 255\n",
        "\n",
        "            out_path = path.replace(DATA_DIR, WORK_DIR + \"/pseudo_masks\")\n",
        "            out_path = os.path.splitext(out_path)[0] + \"_mask.png\"\n",
        "            os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "            Image.fromarray(mask).save(out_path)\n",
        "\n",
        "# Proses training set dalam batch kecil biar hemat memori\n",
        "for xb, yb, pb in tr_dl:\n",
        "    xb = xb.to(DEVICE, non_blocking=True)\n",
        "    save_mask_for_batch(xb, pb)\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Pseudo-masks saved under:\", WORK_DIR + \"/pseudo_masks\")\n"
      ],
      "metadata": {
        "id": "e3aUui0fwHwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d4cfea-8aac-4ad4-cc9e-5cabb9b6dab3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pseudo-masks saved under: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/pseudo_masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Model Multi‑Task (shared encoder + UNet‑decoder + classifier head)"
      ],
      "metadata": {
        "id": "uVZpZgy4wLa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7a) (Opsional) buat pseudo‑mask juga untuk validation\n",
        "Supaya bisa hitung Dice di val set."
      ],
      "metadata": {
        "id": "RHqF4-TwmcnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Generate pseudo-mask untuk VAL set (opsional tapi disarankan) ===\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "import os, numpy as np, torch\n",
        "from PIL import Image\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_cls.eval()\n",
        "target_layer = model_cls.encoder.layer4[-1]\n",
        "tumor_class_names = [k for k in CLASS2IDX.keys() if k.lower() not in [\"no_tumor\",\"notumor\"]]\n",
        "tumor_class_idx = set(CLASS2IDX[k] for k in tumor_class_names)\n",
        "\n",
        "def save_mask_for_batch(x, paths):\n",
        "    logits,_ = model_cls(x)\n",
        "    preds = logits.argmax(1).detach().cpu().numpy()\n",
        "    with GradCAM(model=model_cls, target_layers=[target_layer]) as cam:\n",
        "        for i, path in enumerate(paths):\n",
        "            if int(preds[i]) not in tumor_class_idx:\n",
        "                continue\n",
        "            heatmap = cam(input_tensor=x[i].unsqueeze(0), targets=[ClassifierOutputTarget(int(preds[i]))])[0]\n",
        "            thr = np.percentile(heatmap, 75.0)\n",
        "            mask = (heatmap >= thr).astype(np.uint8) * 255\n",
        "            out_path = path.replace(DATA_DIR, WORK_DIR + \"/pseudo_masks\")\n",
        "            out_path = os.path.splitext(out_path)[0] + \"_mask.png\"\n",
        "            os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "            Image.fromarray(mask).save(out_path)\n",
        "\n",
        "for xb, yb, pb in va_dl:\n",
        "    xb = xb.to(DEVICE, non_blocking=True)\n",
        "    save_mask_for_batch(xb, pb)\n",
        "    if DEVICE==\"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Val pseudo-masks saved under:\", WORK_DIR + \"/pseudo_masks\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKv1HZYTmek2",
        "outputId": "cdb09397-09c0-4537-8ec9-c5f9fc1c8004"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val pseudo-masks saved under: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/pseudo_masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7b) Dataset untuk joint training (pakai pseudo‑mask)"
      ],
      "metadata": {
        "id": "kNzH3ZrWmrnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-7b (fixed): Dataset untuk Multi-Task ====\n",
        "import os, numpy as np, torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "# Pakai ukuran yang sama dengan training klasifikasi\n",
        "IMG_SIZE_MT = IMG_SIZE if \"IMG_SIZE\" in globals() else 224\n",
        "NUM_WORKERS = 2  # sesuai saran Colab\n",
        "\n",
        "# Augmentasi gambar (sama dengan aug_train/aug_val yang sudah ada)\n",
        "# Kita pakai aug_train & aug_val dari Step-3\n",
        "aug_mask_resize = A.Compose([\n",
        "    A.Resize(IMG_SIZE_MT, IMG_SIZE_MT),\n",
        "    albumentations.pytorch.ToTensorV2()\n",
        "])\n",
        "\n",
        "def load_pseudo_mask(path: str):\n",
        "    \"\"\"Load pseudo-mask (0/1). Jika tidak ada, kembalikan mask nol ukuran IMG_SIZE_MT.\"\"\"\n",
        "    mpath = path.replace(DATA_DIR, WORK_DIR + \"/pseudo_masks\")\n",
        "    mpath = os.path.splitext(mpath)[0] + \"_mask.png\"\n",
        "    if os.path.exists(mpath):\n",
        "        m = np.array(Image.open(mpath).convert(\"L\"))  # HxW uint8\n",
        "        m = (m > 127).astype(np.float32)             # 0/1 float\n",
        "    else:\n",
        "        m = np.zeros((IMG_SIZE_MT, IMG_SIZE_MT), dtype=np.float32)\n",
        "    # pastikan ukuran konsisten\n",
        "    if m.shape != (IMG_SIZE_MT, IMG_SIZE_MT):\n",
        "        m = np.array(Image.fromarray((m*255).astype(np.uint8)).resize((IMG_SIZE_MT, IMG_SIZE_MT), resample=Image.NEAREST)) / 255.0\n",
        "    return m\n",
        "\n",
        "class SegSupDataset(Dataset):\n",
        "    def __init__(self, items, aug_img):\n",
        "        self.items = items\n",
        "        self.aug_img = aug_img\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        path, y = self.items[i]\n",
        "        img = np.array(Image.open(path).convert(\"RGB\"))                  # HxWx3\n",
        "        m   = load_pseudo_mask(path)                                     # HxW (float32, 0..1)\n",
        "\n",
        "        img_t = self.aug_img(image=img)[\"image\"]                         # [3,H,W]\n",
        "        m_t   = torch.from_numpy(m).unsqueeze(0).float()                 # [1,H,W]  <<< FIX: tanpa dimensi ekstra\n",
        "\n",
        "        return img_t, y, m_t, path\n",
        "\n",
        "# Dataloader\n",
        "seg_tr = SegSupDataset(train_paths, aug_train)\n",
        "seg_va = SegSupDataset(val_paths,   aug_val)\n",
        "\n",
        "seg_tr_dl = DataLoader(seg_tr, batch_size=32, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "seg_va_dl = DataLoader(seg_va, batch_size=32, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(\"Seg loaders -> train:\", len(seg_tr_dl), \"val:\", len(seg_va_dl))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3QCbciZms3G",
        "outputId": "053a3d88-83b3-4f2b-93cc-2769482a5e19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seg loaders -> train: 152 val: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7c) Arsitektur Multi‑Task (ResNet18 features + UNet‑decoder)"
      ],
      "metadata": {
        "id": "1XHylX3imxyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Model Multi-Task (ResNet18 backbone) ====\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNet18Features(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        m = torchvision.models.resnet18(weights=None)\n",
        "        self.conv1=m.conv1; self.bn1=m.bn1; self.relu=m.relu; self.maxpool=m.maxpool\n",
        "        self.layer1=m.layer1; self.layer2=m.layer2; self.layer3=m.layer3; self.layer4=m.layer4\n",
        "        self.out_dim = 512\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x); x=self.bn1(x); x=self.relu(x); c1=self.maxpool(x)  # 1/4\n",
        "        c2=self.layer1(c1)   # 1/4\n",
        "        c3=self.layer2(c2)   # 1/8\n",
        "        c4=self.layer3(c3)   # 1/16\n",
        "        c5=self.layer4(c4)   # 1/32\n",
        "        emb = torch.flatten(F.adaptive_avg_pool2d(c5,1),1)\n",
        "        return [c2,c3,c4,c5], emb\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_c,out_c,3,1,1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_c,out_c,3,1,1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self,x): return self.net(x)\n",
        "\n",
        "class UNetDecoder18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # resnet18: c2=64, c3=128, c4=256, c5=512\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.cb3 = ConvBlock(256+256, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "        self.cb2 = ConvBlock(128+128, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.cb1 = ConvBlock(64+64, 64)\n",
        "        self.up0 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.out = nn.Conv2d(32, 1, 1)\n",
        "    def forward(self, feats):\n",
        "        c2,c3,c4,c5 = feats\n",
        "        x = self.up3(c5); x = torch.cat([x,c4],1); x = self.cb3(x)\n",
        "        x = self.up2(x);  x = torch.cat([x,c3],1); x = self.cb2(x)\n",
        "        x = self.up1(x);  x = torch.cat([x,c2],1); x = self.cb1(x)\n",
        "        x = self.up0(x);  x = self.out(x)\n",
        "        return x\n",
        "\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = UNetDecoder18()\n",
        "        self.cls_head = nn.Linear(self.encoder.out_dim, num_classes)\n",
        "    def forward(self,x):\n",
        "        feats, emb = self.encoder(x)\n",
        "        seg_logit = self.decoder(feats)   # [B,1,H,W]\n",
        "        cls_logit = self.cls_head(emb)    # [B,C]\n",
        "        return cls_logit, seg_logit\n"
      ],
      "metadata": {
        "id": "zaHKfmrRm1YN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7d) Inisialisasi dengan SSL encoder dan training joint loss"
      ],
      "metadata": {
        "id": "4KZDHC7Xm5qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-7d (fixed): Joint training (classification + segmentation) ====\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = len(CLASS2IDX)\n",
        "LAMBDA_CLS, LAMBDA_SEG = 1.0, 1.0\n",
        "EPOCH_JOINT = 10  # bisa ditambah setelah stabil\n",
        "\n",
        "# ----- Model: gunakan ResNet18Features & MultiTaskNet dari Step-7c -----\n",
        "# Jika belum terdefinisi di notebook (mis. setelah restart), jalankan ulang Step-7c terlebih dulu.\n",
        "assert 'ResNet18Features' in globals() and 'MultiTaskNet' in globals(), \"Jalankan Step-7c lebih dulu (definisi model).\"\n",
        "\n",
        "# Muat encoder SSL (resnet18) ke encoder fitur sebisa mungkin\n",
        "enc_path = f\"{WORK_DIR}/checkpoints/ssl_encoder_resnet18.pt\"\n",
        "mt_enc = ResNet18Features()\n",
        "state_ssl = torch.load(enc_path, map_location=\"cpu\")\n",
        "mt_enc.load_state_dict({k: v for k, v in state_ssl.items() if k in mt_enc.state_dict()}, strict=False)\n",
        "\n",
        "mt_model = MultiTaskNet(mt_enc, NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# Loss & optimizer\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "ce  = nn.CrossEntropyLoss()\n",
        "opt_mt = torch.optim.AdamW(mt_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scaler = GradScaler(device=\"cuda\", enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "def dice_loss(logits, targets, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2*(probs*targets).sum(dim=(2,3))\n",
        "    den = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3)) + eps\n",
        "    return 1 - (num/den).mean()\n",
        "\n",
        "def run_epoch_joint(dl, train=True):\n",
        "    mt_model.train(train)\n",
        "    tot, n, corr = 0.0, 0, 0\n",
        "    for x, y, m, _ in dl:\n",
        "        x = x.to(DEVICE, non_blocking=True)                  # [B,3,H,W]\n",
        "        y = torch.as_tensor(y, device=DEVICE)                # [B]\n",
        "        m = m.to(DEVICE)                                     # [B,1,H,W]\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
        "            cls_log, seg_log = mt_model(x)                   # seg_log: [B,1,h,w]\n",
        "            # >>> Samakan ukuran mask dengan output decoder <<<\n",
        "            if m.shape[-2:] != seg_log.shape[-2:]:\n",
        "                m = F.interpolate(m, size=seg_log.shape[-2:], mode='nearest')  # [B,1,h,w]\n",
        "\n",
        "            loss_cls = ce(cls_log, y)\n",
        "            loss_seg = 0.5*bce(seg_log, m) + 0.5*dice_loss(seg_log, m)\n",
        "            loss = LAMBDA_CLS*loss_cls + LAMBDA_SEG*loss_seg\n",
        "\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt_mt)\n",
        "            scaler.update()\n",
        "            opt_mt.zero_grad(set_to_none=True)\n",
        "\n",
        "        tot += loss.item() * x.size(0); n += x.size(0)\n",
        "        corr += (cls_log.argmax(1) == y).sum().item()\n",
        "\n",
        "    return tot / max(1, n), corr / max(1, n)\n",
        "\n",
        "for ep in range(EPOCH_JOINT):\n",
        "    tr_l, tr_a = run_epoch_joint(seg_tr_dl, True)\n",
        "    va_l, va_a = run_epoch_joint(seg_va_dl, False)\n",
        "    print(f\"[JOINT] {ep+1}/{EPOCH_JOINT}  train {tr_l:.4f}/{tr_a:.3f}  val {va_l:.4f}/{va_a:.3f}\")\n",
        "\n",
        "ckpt_mt = f\"{WORK_DIR}/checkpoints/multitask_resnet18.pt\"\n",
        "torch.save(mt_model.state_dict(), ckpt_mt)\n",
        "print(\"Saved:\", ckpt_mt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NSyf_upm8qV",
        "outputId": "7050987d-27fb-4f01-c290-ab2aff1fc3a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[JOINT] 1/10  train 1.4421/0.708  val 0.9962/0.827\n",
            "[JOINT] 2/10  train 1.0027/0.817  val 0.8294/0.842\n",
            "[JOINT] 3/10  train 0.8893/0.843  val 0.7387/0.876\n",
            "[JOINT] 4/10  train 0.8272/0.858  val 0.6758/0.896\n",
            "[JOINT] 5/10  train 0.7726/0.881  val 0.6490/0.910\n",
            "[JOINT] 6/10  train 0.7639/0.881  val 0.6562/0.901\n",
            "[JOINT] 7/10  train 0.7340/0.890  val 0.5998/0.917\n",
            "[JOINT] 8/10  train 0.7027/0.900  val 0.5693/0.930\n",
            "[JOINT] 9/10  train 0.6904/0.900  val 0.5598/0.932\n",
            "[JOINT] 10/10  train 0.6814/0.908  val 0.5745/0.925\n",
            "Saved: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/checkpoints/multitask_resnet18.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step‑8: Evaluasi & Visualisasi.\n",
        "Blok di bawah ini melakukan:\n",
        "\n",
        "Evaluasi klasifikasi di test set (pakai head klasifikasi dari model multitask).\n",
        "\n",
        "Evaluasi segmentasi (Dice) terhadap pseudo‑mask di validation set.\n",
        "\n",
        "Simpan overlay prediksi mask di atas citra untuk portofolio.\n",
        "\n"
      ],
      "metadata": {
        "id": "il4Uuq3GwQHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑8a — Load model multitask (kalau belum ada di RAM)"
      ],
      "metadata": {
        "id": "sniOaXYFrIAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-8a: Load model multitask (opsional kalau kernel baru) ====\n",
        "import torch, torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_WORKERS = 2\n",
        "ckpt_mt = f\"{WORK_DIR}/checkpoints/multitask_resnet18.pt\"\n",
        "\n",
        "# Definisi model sama dengan Step-7c\n",
        "class ResNet18Features(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        m = torchvision.models.resnet18(weights=None)\n",
        "        self.conv1=m.conv1; self.bn1=m.bn1; self.relu=m.relu; self.maxpool=m.maxpool\n",
        "        self.layer1=m.layer1; self.layer2=m.layer2; self.layer3=m.layer3; self.layer4=m.layer4\n",
        "        self.out_dim = 512\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x); x=self.bn1(x); x=self.relu(x); c1=self.maxpool(x)\n",
        "        c2=self.layer1(c1); c3=self.layer2(c2); c4=self.layer3(c3); c5=self.layer4(c4)\n",
        "        emb = torch.flatten(F.adaptive_avg_pool2d(c5,1),1)\n",
        "        return [c2,c3,c4,c5], emb\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_c,out_c,3,1,1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_c,out_c,3,1,1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self,x): return self.net(x)\n",
        "\n",
        "class UNetDecoder18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.cb3 = ConvBlock(256+256, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "        self.cb2 = ConvBlock(128+128, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.cb1 = ConvBlock(64+64, 64)\n",
        "        self.up0 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.out = nn.Conv2d(32, 1, 1)\n",
        "    def forward(self, feats):\n",
        "        c2,c3,c4,c5 = feats\n",
        "        x = self.up3(c5); x = torch.cat([x,c4],1); x = self.cb3(x)\n",
        "        x = self.up2(x);  x = torch.cat([x,c3],1); x = self.cb2(x)\n",
        "        x = self.up1(x);  x = torch.cat([x,c2],1); x = self.cb1(x)\n",
        "        x = self.up0(x);  x = self.out(x)\n",
        "        return x\n",
        "\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = UNetDecoder18()\n",
        "        self.cls_head = nn.Linear(self.encoder.out_dim, num_classes)\n",
        "    def forward(self,x):\n",
        "        feats, emb = self.encoder(x)\n",
        "        seg_logit = self.decoder(feats)\n",
        "        cls_logit = self.cls_head(emb)\n",
        "        return cls_logit, seg_logit\n",
        "\n",
        "NUM_CLASSES = len(CLASS2IDX)\n",
        "mt_model = MultiTaskNet(ResNet18Features(), NUM_CLASSES).to(DEVICE)\n",
        "mt_model.load_state_dict(torch.load(ckpt_mt, map_location=DEVICE))\n",
        "mt_model.eval()\n",
        "print(\"Loaded multitask model from:\", ckpt_mt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8H2YRGwrWw6",
        "outputId": "17404b43-0716-4284-aa5e-0007de3bcb05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded multitask model from: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/checkpoints/multitask_resnet18.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑8b — Evaluasi klasifikasi di Test Set"
      ],
      "metadata": {
        "id": "v1a9TkNsrdMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-8b: Klasifikasi (test set) ====\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# te_dl dibuat di Step-3 (SupervisedMRIDataset + aug_val)\n",
        "all_y, all_p = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb, _ in te_dl:\n",
        "        xb = xb.to(DEVICE)\n",
        "        logits, _ = mt_model(xb)     # pakai head klasifikasi dari model multitask\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "        all_p.append(probs); all_y.extend(yb)\n",
        "\n",
        "all_p = np.vstack(all_p)\n",
        "pred = all_p.argmax(1)\n",
        "\n",
        "# pretty names (opsional)\n",
        "try:\n",
        "    target_names = [display_name(i) for i in range(NUM_CLASSES)]\n",
        "except:\n",
        "    IDX2CLASS = {v:k for k,v in CLASS2IDX.items()}\n",
        "    target_names = [IDX2CLASS[i] for i in range(NUM_CLASSES)]\n",
        "\n",
        "print(classification_report(all_y, pred, target_names=target_names, digits=4))\n",
        "print(confusion_matrix(all_y, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9lR7bKreRa",
        "outputId": "c040b3da-8e00-4e30-aeba-3633a0e7ede0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "         glioma     0.9255    0.8700    0.8969       300\n",
            "     meningioma     0.8715    0.7092    0.7820       306\n",
            "       no_tumor     0.9076    0.9704    0.9379       405\n",
            "pituitary_tumor     0.8559    0.9900    0.9181       300\n",
            "\n",
            "       accuracy                         0.8909      1311\n",
            "      macro avg     0.8901    0.8849    0.8837      1311\n",
            "   weighted avg     0.8915    0.8909    0.8876      1311\n",
            "\n",
            "[[261  27   0  12]\n",
            " [ 15 217  40  34]\n",
            " [  4   4 393   4]\n",
            " [  2   1   0 297]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑8c — Evaluasi segmentasi (Dice) di Validation\n",
        "Kita bandingkan prediksi segmen dengan pseudo‑mask val (weak label, jadi Dice hanyalah indikasi kasar)."
      ],
      "metadata": {
        "id": "gSTGPTBDrjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-8c: Dice di validation (vs pseudo-mask) ====\n",
        "import numpy as np\n",
        "dice_scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb, mb, _ in seg_va_dl:   # seg_va_dl dibuat di Step-7b\n",
        "        xb = xb.to(DEVICE); mb = mb.to(DEVICE)      # xb:[B,3,H,W], mb:[B,1,H,W]\n",
        "        _, seg_log = mt_model(xb)                   # [B,1,h,w]\n",
        "        # samakan ukuran mask -> output\n",
        "        if mb.shape[-2:] != seg_log.shape[-2:]:\n",
        "            mb = torch.nn.functional.interpolate(mb, size=seg_log.shape[-2:], mode='nearest')\n",
        "        pr = (torch.sigmoid(seg_log) > 0.5).float()\n",
        "        inter = (pr*mb).sum(dim=(2,3))\n",
        "        den   = pr.sum(dim=(2,3)) + mb.sum(dim=(2,3)) + 1e-6\n",
        "        dice  = (2*inter/den).mean().item()\n",
        "        dice_scores.append(dice)\n",
        "\n",
        "print(\"Val Dice (vs pseudo-mask):\", float(np.mean(dice_scores)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnWj15d_rkrh",
        "outputId": "3fe49f9e-47d2-4b05-f88f-f9986305f5bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Dice (vs pseudo-mask): 0.5330317130795231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑8d — Simpan overlay contoh (untuk portfolio)"
      ],
      "metadata": {
        "id": "QpYba7PMrqZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-8d: Simpan overlay segmen (val samples) ====\n",
        "import matplotlib.pyplot as plt, os\n",
        "save_dir = f\"{WORK_DIR}/figures_samples\"; os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "mt_model.eval()\n",
        "saved = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb, mb, paths in seg_va_dl:\n",
        "        xb = xb.to(DEVICE)\n",
        "        cls_log, seg_log = mt_model(xb)\n",
        "        probs = F.softmax(cls_log, dim=1).cpu().numpy()\n",
        "        pr = (torch.sigmoid(seg_log) > 0.5).float().cpu().numpy()\n",
        "        x_np = xb.cpu().numpy().transpose(0,2,3,1)\n",
        "\n",
        "        for i in range(min(4, x_np.shape[0])):\n",
        "            img01 = (x_np[i]-x_np[i].min())/(x_np[i].max()-x_np[i].min()+1e-8)\n",
        "            mask  = pr[i,0]\n",
        "            pred_class = target_names[probs[i].argmax()]\n",
        "            plt.figure()\n",
        "            plt.imshow(img01)\n",
        "            plt.imshow(mask, alpha=0.35)\n",
        "            plt.title(f\"Pred: {pred_class}\")\n",
        "            outp = os.path.join(save_dir, f\"overlay_{saved}.png\")\n",
        "            plt.axis(\"off\"); plt.savefig(outp, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
        "            saved += 1\n",
        "        if saved >= 12:\n",
        "            break\n",
        "\n",
        "print(\"Saved overlays to:\", save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHuZQLzbrri1",
        "outputId": "c8ebc594-48ce-4eea-c40c-0a290aa08483"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved overlays to: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/figures_samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Opsional) ROC‑AUC per kelas (multi‑class)"
      ],
      "metadata": {
        "id": "y-usikD4rzQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Optional: ROC-AUC macro/micro ====\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "y_onehot = np.eye(NUM_CLASSES)[np.array(all_y)]\n",
        "try:\n",
        "    auc_macro = roc_auc_score(y_onehot, all_p, average=\"macro\", multi_class=\"ovr\")\n",
        "    auc_micro = roc_auc_score(y_onehot, all_p, average=\"micro\", multi_class=\"ovr\")\n",
        "    print(f\"ROC-AUC macro: {auc_macro:.4f} | micro: {auc_micro:.4f}\")\n",
        "except Exception as e:\n",
        "    print(\"AUC error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kOravb1r1Yz",
        "outputId": "d635248c-a71f-4415-9a61-62927aca1a05"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC macro: 0.9842 | micro: 0.9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9) Robustness testing\n",
        "Tambahkan stress‑tests: noise ↑, motion blur ↑, bias‑field dan lihat drop akurasi/Dice."
      ],
      "metadata": {
        "id": "Uhkk3p_gwVQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑9a — Robustness testing (artefak MRI)\n",
        "Uji ketahanan klasifikasi terhadap noise & motion blur. Kita buat fungsi evaluasi cepat di validation."
      ],
      "metadata": {
        "id": "e_15iBTTtMUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-9a: Robustness testing (val set) ====\n",
        "import albumentations as A, albumentations.pytorch\n",
        "import numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "mt_model.eval()\n",
        "\n",
        "def eval_with_aug(dl, aug):\n",
        "    all_y, all_p = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in dl:\n",
        "            xb = xb.cpu().numpy().transpose(0,2,3,1)   # B,H,W,3\n",
        "            x_aug = []\n",
        "            for i in range(xb.shape[0]):\n",
        "                xi = xb[i]\n",
        "                # map ke [0,255] uint8 untuk Albumentations\n",
        "                xi = ( (xi - xi.min()) / (xi.max() - xi.min() + 1e-8) * 255 ).astype(np.uint8)\n",
        "                xi = aug(image=xi)[\"image\"]            # tensor [3,H,W]\n",
        "                x_aug.append(xi)\n",
        "            x_aug = torch.stack(x_aug).to(DEVICE)\n",
        "            logits, _ = mt_model(x_aug)\n",
        "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "            all_p.append(probs); all_y.extend(yb)\n",
        "    all_p = np.vstack(all_p)\n",
        "    acc = (all_p.argmax(1) == np.array(all_y)).mean()\n",
        "    return acc\n",
        "\n",
        "# baseline (tanpa artefak) pakai va_dl langsung\n",
        "from copy import deepcopy\n",
        "acc_clean = eval_with_aug(va_dl, A.Compose([A.NoOp(), A.Normalize(), albumentations.pytorch.ToTensorV2()]))\n",
        "print(\"Acc clean (val):\", acc_clean)\n",
        "\n",
        "# noise levels\n",
        "for sigma in [5, 15, 25, 35]:\n",
        "    aug = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "        A.GaussNoise(var_limit=(sigma, sigma), p=1.0),\n",
        "        A.Normalize(),\n",
        "        albumentations.pytorch.ToTensorV2(),\n",
        "    ])\n",
        "    acc = eval_with_aug(va_dl, aug)\n",
        "    print(f\"Acc with GaussNoise sigma={sigma}: {acc:.4f}\")\n",
        "\n",
        "# motion blur levels\n",
        "for bl in [3, 7, 11, 15]:\n",
        "    aug = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "        A.MotionBlur(blur_limit=bl, p=1.0),\n",
        "        A.Normalize(),\n",
        "        albumentations.pytorch.ToTensorV2(),\n",
        "    ])\n",
        "    acc = eval_with_aug(va_dl, aug)\n",
        "    print(f\"Acc with MotionBlur {bl}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsMofsNftPak",
        "outputId": "1e3e4641-acc6-4c27-c0c5-fc3de998ad60"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc clean (val): 0.8739789964994166\n",
            "Acc with GaussNoise sigma=5: 0.8903\n",
            "Acc with GaussNoise sigma=15: 0.8880\n",
            "Acc with GaussNoise sigma=25: 0.8798\n",
            "Acc with GaussNoise sigma=35: 0.8751\n",
            "Acc with MotionBlur 3: 0.9020\n",
            "Acc with MotionBlur 7: 0.8915\n",
            "Acc with MotionBlur 11: 0.8891\n",
            "Acc with MotionBlur 15: 0.8623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑9b — Calibration (ECE) & confidence hist\n",
        "Kita cek Expected Calibration Error (ECE) dan reliabilitas confidence model."
      ],
      "metadata": {
        "id": "--dalvs5tWcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-9b: Calibration (ECE) on test set ====\n",
        "import numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def collect_probs(dl):\n",
        "    mt_model.eval()\n",
        "    all_y, all_p = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in dl:\n",
        "            xb = xb.to(DEVICE)\n",
        "            probs = F.softmax(mt_model(xb)[0], dim=1).cpu().numpy()\n",
        "            all_p.append(probs); all_y.extend(yb)\n",
        "    return np.array(all_y), np.vstack(all_p)\n",
        "\n",
        "y_true, p = collect_probs(te_dl)\n",
        "conf = p.max(1)\n",
        "pred = p.argmax(1)\n",
        "acc = (pred == y_true).astype(np.float32)\n",
        "\n",
        "def expected_calibration_error(conf, correct, n_bins=15):\n",
        "    bins = np.linspace(0, 1, n_bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        lo, hi = bins[i], bins[i+1]\n",
        "        idx = (conf >= lo) & (conf < hi)\n",
        "        if idx.sum() == 0: continue\n",
        "        bin_acc = correct[idx].mean()\n",
        "        bin_conf = conf[idx].mean()\n",
        "        ece += (idx.mean()) * abs(bin_conf - bin_acc)\n",
        "    return float(ece)\n",
        "\n",
        "ece = expected_calibration_error(conf, (pred==y_true))\n",
        "print(f\"ECE (test): {ece:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBPFkASztXuZ",
        "outputId": "b4fb9e5a-0ce9-43b1-ae48-500782b0ad56"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECE (test): 0.0253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑9c — Test‑Time Augmentation (TTA) sederhana\n",
        "Kadang TTA meningkatkan akurasi tanpa training ulang."
      ],
      "metadata": {
        "id": "FKSdi5Uitb-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-9c: TTA di test set ====\n",
        "import numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "import albumentations as A, albumentations.pytorch\n",
        "\n",
        "tta_transforms = [\n",
        "    A.Compose([A.HorizontalFlip(p=1.0), A.Normalize(), albumentations.pytorch.ToTensorV2()]),\n",
        "    A.Compose([A.RandomBrightnessContrast(0.1,0.1,p=1.0), A.Normalize(), albumentations.pytorch.ToTensorV2()]),\n",
        "    A.Compose([A.NoOp(), A.Normalize(), albumentations.pytorch.ToTensorV2()]),\n",
        "]\n",
        "\n",
        "def tta_predict_batch(xb_np):  # xb_np: B,H,W,3 in [0,1]\n",
        "    probs_sum = None\n",
        "    for aug in tta_transforms:\n",
        "        xs = []\n",
        "        for i in range(xb_np.shape[0]):\n",
        "            xi = (xb_np[i]*255).astype(np.uint8)\n",
        "            xi = aug(image=xi)[\"image\"]\n",
        "            xs.append(xi)\n",
        "        xs = torch.stack(xs).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            pr = F.softmax(mt_model(xs)[0], dim=1).cpu().numpy()\n",
        "        probs_sum = pr if probs_sum is None else probs_sum + pr\n",
        "    return probs_sum / len(tta_transforms)\n",
        "\n",
        "# evaluate\n",
        "all_y, all_p = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb, _ in te_dl:\n",
        "        x = xb.cpu().numpy().transpose(0,2,3,1)\n",
        "        # normalize to [0,1]\n",
        "        x = (x - x.min())/(x.max()-x.min()+1e-8)\n",
        "        pr = tta_predict_batch(x)\n",
        "        all_p.append(pr); all_y.extend(yb)\n",
        "all_p = np.vstack(all_p)\n",
        "tta_acc = (all_p.argmax(1) == np.array(all_y)).mean()\n",
        "print(\"TTA accuracy (test):\", tta_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP_hnhl0tfRb",
        "outputId": "b495a7d7-b0d9-4c02-9cc3-d297e3da4730"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTA accuracy (test): 0.8527841342486652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑9d — Export model & demo inference\n",
        "Simpan TorchScript + fungsi inference untuk deployment ringan."
      ],
      "metadata": {
        "id": "sF1-pYG3thMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-9d: Export TorchScript + fungsi inference ====\n",
        "import torch, torch.nn.functional as F\n",
        "\n",
        "mt_model.eval()\n",
        "example = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
        "traced = torch.jit.trace(mt_model, example)\n",
        "ts_path = f\"{WORK_DIR}/checkpoints/multitask_resnet18_ts.pt\"\n",
        "traced.save(ts_path)\n",
        "print(\"Saved TorchScript:\", ts_path)\n",
        "\n",
        "# fungsi inference 1 gambar (np.ndarray HxWx3 uint8)\n",
        "import numpy as np, albumentations as A, albumentations.pytorch\n",
        "from PIL import Image\n",
        "\n",
        "preproc = A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.Normalize(), albumentations.pytorch.ToTensorV2()])\n",
        "\n",
        "IDX2CLASS = {v:k for k,v in CLASS2IDX.items()}\n",
        "DISPLAY_MAP = {\"pituitary\":\"pituitary_tumor\", \"notumor\":\"no_tumor\"}\n",
        "\n",
        "def predict_image(img_path, thr=0.5):\n",
        "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    x = preproc(image=img)[\"image\"].unsqueeze(0).to(DEVICE)     # [1,3,H,W]\n",
        "    with torch.no_grad():\n",
        "        cls_log, seg_log = mt_model(x)\n",
        "        probs = F.softmax(cls_log, dim=1)[0].cpu().numpy()\n",
        "        seg = (torch.sigmoid(seg_log)[0,0].cpu().numpy() > thr).astype(np.uint8)\n",
        "    cls_idx = probs.argmax()\n",
        "    raw = IDX2CLASS[cls_idx]\n",
        "    name = DISPLAY_MAP.get(raw, raw)\n",
        "    return name, float(probs.max()), seg\n",
        "\n",
        "# contoh pakai 1 file test\n",
        "sample_path = test_paths[0][0]\n",
        "pred_name, conf, seg_mask = predict_image(sample_path)\n",
        "print(\"Pred:\", pred_name, \"conf:\", conf, \"\\nfrom:\", sample_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "515cnySBtlYe",
        "outputId": "756633a9-dae6-4d87-f711-10389b5b17da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved TorchScript: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/checkpoints/multitask_resnet18_ts.pt\n",
            "Pred: glioma conf: 0.8414149880409241 \n",
            "from: /content/drive/MyDrive/Prep PhD/Portofolio/Data/MRI_Brain/Testing/glioma/Te-glTr_0001.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step‑9e — “Packing hasil” untuk portfolio\n",
        "Simpan tabel metrik (classification report) ke .txt atau .csv.\n",
        "\n",
        "Simpan overlay (sudah ada di Step‑8d) + beberapa Grad‑CAM contoh (opsional).\n",
        "\n",
        "Tulis README ringkas + mini‑paper (PDF)."
      ],
      "metadata": {
        "id": "rBTal-2lt2H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Step-9e: Simpan classification report ====\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# dari Step-8b kita punya all_y, all_p\n",
        "report_str = classification_report(all_y, all_p.argmax(1), target_names=target_names, digits=4)\n",
        "out_txt = f\"{WORK_DIR}/reports/classification_report.txt\"\n",
        "import os\n",
        "os.makedirs(f\"{WORK_DIR}/reports\", exist_ok=True)\n",
        "with open(out_txt, \"w\") as f:\n",
        "    f.write(report_str)\n",
        "print(\"Saved:\", out_txt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQxq1unt3VD",
        "outputId": "1427ca88-e96d-4e59-d02c-f616286660f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/Prep PhD/Portofolio/brain_mri_project/reports/classification_report.txt\n"
          ]
        }
      ]
    }
  ]
}